{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For days 2-3: transfer learning using VGG16, model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os;\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True';"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf;\n",
    "import numpy as np;\n",
    "import pandas as pd;\n",
    "import matplotlib.pyplot as plt;\n",
    "import tensorflow.keras.backend as kb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5216 images belonging to 2 classes.\n",
      "Found 16 images belonging to 2 classes.\n",
      "Found 624 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    width_shift_range=0.05,\n",
    "    height_shift_range=0.15,\n",
    "    rotation_range=10,\n",
    "    zoom_range=0.1,\n",
    ")\n",
    "validation_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    '/users/chensuyun/Dropbox/chest-x-ray/data/train',\n",
    "    target_size=(224,224),\n",
    "    batch_size=100,\n",
    "    class_mode=\"binary\",\n",
    "    #color_mode=\"grayscale\",\n",
    "    shuffle=True,\n",
    ")\n",
    " \n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "    '/users/chensuyun/Dropbox/chest-x-ray/data/val',\n",
    "    target_size=(224,224),\n",
    "    class_mode=\"binary\",\n",
    "    #color_mode=\"grayscale\",\n",
    "    shuffle=False,\n",
    "    batch_size=1,\n",
    ")\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    '/users/chensuyun/Dropbox/chest-x-ray/data/test',\n",
    "    target_size=(224,224),\n",
    "    class_mode=\"binary\",\n",
    "    #color_mode=\"grayscale\",\n",
    "    shuffle=False,\n",
    "    batch_size=1,\n",
    ")\n",
    "# num classes\n",
    "num_classes = 2;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory Number\n",
    "i = 1;\n",
    "while(1):\n",
    "    if os.path.isdir('./{}' . format(i)) == False:\n",
    "        break;\n",
    "    else:\n",
    "        i = i + 1;\n",
    "savedir = './{}' . format(i);\n",
    "os.mkdir(savedir);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loss function\n",
    "def custom_loss(y_pred, y_true):\n",
    "    custom_loss=kb.mean(kb.pow((y_true-y_pred),2))\n",
    "\n",
    "    return custom_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 53 steps, validate for 624 steps\n",
      "Epoch 1/3\n",
      "53/53 [==============================] - 1852s 35s/step - loss: 0.1431 - custom_loss: 0.1431 - accuracy: 0.8025 - val_loss: 0.1533 - val_custom_loss: 0.1533 - val_accuracy: 0.7660\n",
      "Epoch 2/3\n",
      "53/53 [==============================] - 1788s 34s/step - loss: 0.0848 - custom_loss: 0.0848 - accuracy: 0.8796 - val_loss: 0.1075 - val_custom_loss: 0.1075 - val_accuracy: 0.8510\n",
      "Epoch 3/3\n",
      "53/53 [==============================] - 1800s 34s/step - loss: 0.0728 - custom_loss: 0.0728 - accuracy: 0.8974 - val_loss: 0.0962 - val_custom_loss: 0.0962 - val_accuracy: 0.8734\n",
      "Test loss: 0.09619553975918776\n",
      "Test accuracy: 0.8733974\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential()\n",
    "pmodel=tf.keras.applications.vgg16.VGG16(weights='imagenet',include_top=False,input_tensor=tf.keras.layers.Input(shape=(224,224,3)));\n",
    "pmodel.trainable = False;\n",
    "model.add(pmodel);\n",
    "model.add(tf.keras.layers.GlobalAveragePooling2D());\n",
    "model.add(tf.keras.layers.Flatten());\n",
    "model.add(tf.keras.layers.Dense(256));\n",
    "model.add(tf.keras.layers.Dropout(0.5));\n",
    "model.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
    "model.compile(loss=custom_loss, optimizer=tf.keras.optimizers.RMSprop(), metrics=[custom_loss,'accuracy'])\n",
    "\n",
    "# fit\n",
    "history = model.fit(train_generator, epochs=3, validation_data=test_generator)\n",
    "score = model.evaluate(test_generator, verbose=0)\n",
    "print('Test loss:', score[0]);\n",
    "print('Test accuracy:', score[2]);\n",
    "model.save_weights(savedir + '/dense-layer_weights.h5');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.09619553975918776, 0.096195534, 0.8733974]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score # 0: total loss = MSE + regularization, 1: MSE, 2: accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.09619553975918776, 0.096195534, 0.8733974]\n"
     ]
    }
   ],
   "source": [
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': [0.14447055884459817, 0.0857369731397488, 0.07351797073222469], 'custom_loss': [0.14312413, 0.084786125, 0.0727654], 'accuracy': [0.80253065, 0.87960124, 0.89743096], 'val_loss': [0.15325428635842633, 0.10745886233500193, 0.09619553975918776], 'val_custom_loss': [0.1532543, 0.10745892, 0.096195534], 'val_accuracy': [0.76602566, 0.85096157, 0.8733974]}\n"
     ]
    }
   ],
   "source": [
    "print(history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# save history\n",
    "history_json = pd.DataFrame(history.history);\n",
    "with open(savedir + '/history.json', 'w') as f:\n",
    "    history_json.to_json(f);\n",
    "\n",
    "# Plot training & validation accuracy values\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.savefig(savedir + '/accuracy.png');\n",
    "plt.clf();\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.savefig(savedir + '/loss.png');\n",
    "plt.clf();\n",
    "\n",
    "# Plot training & validation loss without regularization term\n",
    "plt.plot(history.history['custom_loss'])\n",
    "plt.plot(history.history['val_custom_loss'])\n",
    "plt.title('Model loss without regularization term')\n",
    "plt.ylabel('Loss without Regularization Term')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.savefig(savedir + '/loss-without-regularization.png');\n",
    "plt.clf();\n",
    "\n",
    "# Plot reconstruction error\n",
    "plt.plot(np.array(history.history['loss'])-np.array(history.history['custom_loss']))\n",
    "plt.plot(np.array(history.history['val_loss'])-np.array(history.history['val_custom_loss']))\n",
    "plt.title('Penalty based on reconstruction error')\n",
    "plt.ylabel('Penality')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.savefig(savedir + '/regularization.png');\n",
    "plt.clf();\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "vgg16 (Model)                (None, 7, 7, 512)         14714688  \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 14,846,273\n",
      "Trainable params: 131,585\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[  81]\n",
      " [1296]], shape=(2, 1), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[  81]\n",
      " [1296]], shape=(2, 1), dtype=int32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TensorShape([2, 1])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = [[3], [6]]\n",
    "y=tf.math.square(tf.math.square(x),tf.math.square(x))\n",
    "z=tf.math.pow(x,4)\n",
    "print(y)\n",
    "print(z)\n",
    "z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
